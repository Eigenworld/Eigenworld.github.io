---
title: "Home"
layout: homelay
sitemap: false
permalink: /
---

<style>
code {padding: 6px 8px; font-size: 90%;}
</style>

# Welcome!

I am a four-year Ph.D. student in Computer Science working with <a href="https://www.researchgate.net/scientific-contributions/Yuanzhi-Cheng-57525128" target="_blank">Professor Yuanzhi Cheng</a> on interpretable artificial intelligence at the <a href="http://en.hitsz.edu.cn" target="_blank">Harbin Institute of Technology</a>. Specifically, we combine deep neural networks with graph techniques to effectively explain and optimize the current neural network structure. Check out our recent 2022 preprints on the publications page.

I will complete my Ph.D. in Computer Science by October 2023. Now, I am applying for a postdoctoral position.  I began my studies (B.S.) at the Qingdao Technological University in Network Engineering and continued with a Masters (M.S.) in Computer Science (Summa Cum Laude) studying recommendation system and graph theory at the Northeast Forestry University. During 2017-2019, I worked as a helicopter pilot at Aviation Industry Corporation of China, Ltd. (AVIC). We fly helicopters (AS-350B2) for forest protection and fire prevention, geological exploration, aerial photography and other tasks. I also led an AR aviation tourism project in 2018. In this role I spent time working as a prototype engineer, a aeronautical system modeler, and a flying data analyst. Currently,  I am pursuing research at the intersection of interpretable artificial intelligence and complex network dynamics.

### Exploration of Deep Learning Technology

My recent research activity centers around the structural analysis and optimization of Batch Normalization and Transformer by leveraging recent advancements in deep neural networks and graph theory. Check out this quick 3 minute <a href="https://www.youtube.com/watch?v=ZYbB9TayxmQ" target="_blank">video</a> for a snapshot into my current work. I hope to have some publications out shortly surrounding these techniques.

<br/>

<div class="row" style="text-align:center">
<video controls autoplay muted loop width="90%" style="display:inline-block; border-radius: 25px; border:0px solid #FFF;">
  <source src="{{ site.url }}{{ site.baseurl }}/images/videos/My_Scene.mov" type="video/mp4">
  Your browser does not support the video tag.
</video>
  Analysis and Optimization of Modern Neural Network Architecture Based on Graph Theory.
<br/>
Li, Xue et al., *IEEE TPAMI* (2022)
</div>

<br/>

### Graph-Driven Model Analysis

My research investigates the fundamental mechanisms that exist in complex computations of neural networks by leveraging graph drawing strategies, randomness analysis, and reduced-order modeling strategies. These mechanisms are of importance as they govern the undestanding, design, and application of artificial intelligence algorithms. The current popular explainability research theory can only provide limited insight into these mechanisms. In much of my research, I look to expose and exploit *combinatorial, geometric and random* structure in machine learning problems, to learn and verify various properties of models from the data and the algorithm framework to yield reduced-order models that are both explainable and general (i.e. applicable to other neural computing processes). In short, this research is skeptical of the existing AI technology. Unfortunately, at the doctoral stage, I only completed part of my plan. The progress of all work is as follows：

&#8194;	● **Interpretability and architecture design of message passing of graph neural network.**

​		&#8194;--Completion：100% for current GNNs

​		&#8194;--Completion：30% for distributed GNNs

​	&#8194;● **Interpretability and optimization of attention mechanism.**

​        &#8194;--Completion：100% for graph attention

​		&#8194;--Completion：20% for Transformer attention

​	&#8194;● **Interpretability and optimization of X-Norm (e.g., BatchNorm and LayerNorm)                                                          		(The theoretical part is almost completed and has been verified.)**

​		&#8194;--Completion：60%

​	&#8194;● **What is Transformer? A perspective from graph generation and alignment.**

​		&#8194;--Completion：20%

<br/>

### Scholars who keep in touch

**Yehuda Koren**: He is a staff research scientist at Google. Prior to this, he was a senior research scientist at Yahoo! Research and a principal staff member of AT&T Labs-Research.

**Mehak Khan**: She is working as a Senior Researcher (Post-Doc) at Oslo Metropolitan University, where my research focuses on Graph Neural Networks and related algorithms for Citation Networks.
